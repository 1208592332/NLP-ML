# <center> 第 7 章 自然语言处理 </center>


> 本章导读：本章开始进入自然语言处理篇章，作为开篇第一章，有必要给读者详细介绍自然语言处理的全貌。本章开篇直击要点即自然语言处理的任务和限制。进而介绍其所涉及的主要技术范畴，并对这些技术方向进行图文介绍。针对当前自然语言处理的难点进行详细剖析讲解，最后对2017年以后自然语言处理发展进行展望。
##	7.1 自然语言处理的任务和限制
> 任务和限制

NLP是一种很吸引人的人机交互方式。早期的语言处理系统如SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。
由于理解自然语言，需要关于外在世界的广泛知识以及运用操作这些知识的能力，自然语言认知，同时也被视为一个人工智能完备的问题。在自然语言处理中，"理解"的定义也变成一个主要的问题。


> 一些NLP面临的问题实例：

句子“我们把香蕉给猴子，因为(它们)饿了”和“我们把香蕉给猴子，因为(它们)熟透了”有同样的结构。但是代词“它们”在第一句中指的是“猴子”，在第二句中指的是“香蕉”。如果不了解猴子和香蕉的属性，无法区分。(英文的it没有区分，但在中文里“它”和“它”是有区别的，只是代词在中文里常常被省略，因此需区别属性并且标示出来)

##	7.2 自然语言处理的主要技术范畴
###	7.2.1 语音合成

> 语音合成（Speech synthesis）/文本朗读（Text to speech）


语音合成是将人类语音用人工的方式所产生。若是将电脑系统用在语音合成上，则称为语音合成器，而语音合成器可以用软/硬件所实现。文字转语音（text-to-speech，TTS）系统则是将一般语言的文字转换为语音，其他的系统可以描绘语言符号的表示方式，就像音标转换至语音一样。

<center>
![](https://i.imgur.com/gIyBE03.jpg)

图7-1 语音合成
</center>

一个语音合成器的质量通常是决定于人声的相似度以及语义是否能被了解。一个清晰的文字转语音程序应该提供人类在视觉受到伤害或是得到失读症时，能够听到并且在个人电脑上完成工作。从80年代早期开始，许多的电脑操作系统已经包含了语音合成器了。

语音合成的应用包括：智能仪表、智能玩具、电子地图、电子导游、电子词典等。

###	7.2.2 语音识别
> 语音识别（Speech recognition）


语音识别（speech recognition）技术，也被称为语音转文本识别（英语：Speech To Text, STT），其目标是以电脑自动将人类的语音内容转换为相应的文字。与说话人识别及说话人确认不同，后者尝试识别或确认发出语音的说话人而非其中所包含的词汇内容。


<center>
![](https://i.imgur.com/Gyb1PWs.jpg)

图7-2 语音识别
</center>

语音识别技术的应用包括语音拨号、语音导航、室内设备控制、语音文档检索、简单的听写数据录入等。语音识别技术与其他自然语言处理技术如机器翻译及语音合成技术相结合，可以构建出更加复杂的应用，例如语音到语音的翻译。

语音识别技术所涉及的领域包括：信号处理、模式识别、概率论和信息论、发声机理和听觉机理、人工智能等等。

###	7.2.3 中文自动分词
> 中文自动分词（Chinese word segmentation）

中文自动分词指的是使用计算机自动对中文文本进行词语的切分，即像英文那样使得中文句子中的词之间有空格以标识。中文自动分词被认为是中文自然语言处理中的一个最基本的环节。

<center>

![](https://i.imgur.com/siMrWOW.png)

图7-3 中文自动分词
</center>

现有方法包括：

- 基于词典的匹配：前向最大匹配、后向最大匹配。
- 基于字的标注：最大熵模型、条件随机场模型、感知器模型。
- 其它方法：与词性标注结合、与句法分析结合。

###	7.2.4 词性标注
> 词性标注（Part-of-speech tagging）


词性标注（Part-of-Speech tagging 或POS tagging)，又称词类标注或者简称标注，是指在词性标记集已确定，并且词典中每个词都有确定词性的基础上，对一个输入词串转换成相应词性标记串的过程叫做词性标注。

<center>

![](https://i.imgur.com/KlLK1Te.png)

图7-4 中文词性标注
</center>

在汉语中，因为汉语词汇词性多变的情况比较少见，大多词语只有一个词性，或者出现频次最高的词性远远高于第二位的词性，相对比较简单。同时，它也受到一些条件约束。比如：兼类词在具体语境中的词性判定问题、未登录词即新词词性问题、兼类词问题等。

词性标注方法包括：概率方法、隐马尔可夫模型的词性标注方法、机器学习规则的方法等

###	7.2.5 句法分析
> 句法分析（Parsing）

句法分析(Parsing)就是指对句子中的词语语法功能进行分析。比如“我来晚了”，这里“我”是主语，“来”是谓语，“晚了”是补语。

<center>

![](https://i.imgur.com/1SxLnTT.jpg)

图7-5 句法分析
</center>

句法分析在中文信息处理中的主要应用包括：如机器翻译、命名实体识别等。

> 自然语言生成（Natural language generation）


自然语言生成是研究使计算机具有人一样的表达和写作的功能。即能够根据一些关键信息及其在机器内部的表达形式，经过一个规划过程，来自动生成一段高质量的自然语言文本。
自然语言处理包括自然语言理解和自然语言生成。自然语言生成是人工智能和计算语言学的分支,相应的语言生成系统是基于语言信息处理的计算机模型,其工作过程与自然语言分析相反,是从抽象的概念层次开始,通过选择并执行一定的语义和语法规则来生成文本。

###	7.2.6 文本分类
> 文本分类（Text categorization）

文本分类用电脑对文本集按照一定的分类器模型进行自动分类标记。文本分类的总体过程如下：

1. 预处理：将原始语料格式化为同一格式，便于后续的统一处理；
1. 索引：将文档分解为基本处理单元，同时降低后续处理的开销；
1. 统计：词频统计，项（单词、概念）与分类的相关概率；
1. 特征抽取：从文档中抽取出反映文档主题的特征；
1. 分类器：分类器的训练；
1. 评价：分类器的测试结果分析。

<center>

![](https://i.imgur.com/3YWeGx3.png)

图7-6 文本分类
</center>

文本分类常用算法包括：决策树、朴素贝叶斯、神经网络、支持向量机、线性最小平方拟合、kNN、遗传算法、最大熵等。广泛应用于垃圾过滤，新闻分类，词性标注等。

###	7.2.7 文本挖掘
> 文本挖掘

文本挖掘一般指文本处理过程中产生高质量的信息。高质量的信息通常通过分类和预测来产生，如模式识别。文本挖掘通常涉及输入文本的处理过程，产生结构化数据，并最终评价和解释输出。
<center>

![](https://i.imgur.com/3oHq8DE.png)

图7-7 文本挖掘
</center>
典型的文本挖掘方法包括文本分类、文本聚类、信息抽取、概念/实体挖掘、情感分析和观点分析等。

###	7.2.8 信息抽取
> 信息抽取（Information extraction）

信息抽取（Information Extraction）主要是从大量文字数据中自动抽取特定消息作为数据库访问之用的技术。

<center>

![](https://i.imgur.com/jaLGNC1.png)

图7-8 信息抽取
</center>

简单可以理解为从给定文本中抽取重要的信息，比如，时间、地点、人物、事件、原因、结果、数字、日期、货币、专有名词等等。通俗说来，就是要了解谁在什么时候、什么原因、对谁、做了什么事、有什么结果。涉及到实体识别、时间抽取、因果关系抽取等关键技术。

###	7.2.9 问答系统
> 问答系统（Question answering）

问答系统（英语：Question answering），是，当下自然语言处理研究的热点，未来自然语言处理的明日之星。问答系统外部的行为上来看，其与目前主流资讯检索技术有两点不同：首先是查询方式为完整而口语化的问句，再来则是其回传的为高精准度网页结果或明确的答案字串。

<center>

![](https://i.imgur.com/LpFfAH2.jpg)

图7-9 问答系统
</center>

以Ask Jeeves为例，使用者不需要思考该使用什么样的问法才能够得到理想的答案，只需要用口语化的方式直接提问如“请问谁是美国总统？”即可。而系统在了解使用者问句后，会非常清楚地回答“特朗普是美国总统”。从系统内部来看，问答系统使用了大量有别于传统资讯检索系统自然语言处理技术，如自然语言剖析（Natural Language Parsing）、问题分类（Question Classification）、专名辨识（Named Entity Recognition）等等。

###	7.2.10 机器翻译
> 机器翻译（Machine translation）

机器翻译（英语：Machine Translation，经常简写为MT）属于计算语言学的范畴，其研究借由计算机程序将文字或演说从一种自然语言翻译成另一种自然语言。
<center>

![](https://i.imgur.com/eNS65aV.jpg)

图7-10 机器翻译
</center>

简单来说，机器翻译是通过将一个自然语言的字辞取代成另一个语言的字辞。借由使用语料库的技术，可达成更加复杂的自动翻译，包含可更佳的处理不同的文法结构、辞汇辨识、惯用语的对应等。


一般而言，大众使用机器翻译的目的只是为了获知原文句子或段落的要旨，而不是精确的翻译。总的来说，机器翻译的效果并没有达到可以取代人工翻译的程度，所以无法成为正式的翻译。

不过现在已有越来越多的公司尝试以机器翻译的技术来提供其公司网站多语系支援的服务。例如微软公司试将其 MSDN 以机器翻译来自动翻译成多国语言，如上文所说，知识库作为专业领域 ，其文法较为制式化，翻译结果亦更加符合自然语言。

###	7.2.11 文本情感分析
> 文本情感分析

文本情感分析（也称为意见挖掘）是指用自然语言处理、文本挖掘以及计算机语言学等方法来识别和提取原素材中的主观信息。
<center>

![](https://i.imgur.com/xtf9wnu.png)

图7-11 文本情感分析
</center>

通常来说，情感分析的目的是为了找出说话者/作者在某些话题上或者针对一个文本两极的观点的态度。这个态度或许是他或她的个人判断或是评估，也许是他当时的情感状态（就是说，作者在做出这个言论时的情绪状态），或是作者有意向的情感交流（就是作者想要读者所体验的情绪）。


###	7.2.12 自动摘要
> 自动摘要（Automatic summarization）

所谓自动文摘就是利用计算机自动地从原始文献中提取文摘，文摘是全面准确地反映某一文献中心内容地简单连贯的短文。常用方法是自动摘要将文本作为句子的线性序列，将句子视为词的线性序列。
<center>

![](https://i.imgur.com/S78QJlJ.png)

图7-12 自动摘要
</center>

自动摘要可以按照技术类型和信息提取分为如下：

- 技术应用类型：自动提取给定文章的摘要信息、自动计算文章中词的权重、自动计算文章中句子的权重。
- 信息提取：单篇文章的摘要自动提取、大规模文档的摘要自动提取、基于分类的摘要自动提取。
 
###	7.2.13 文字蕴涵
> 文字蕴涵（Textual entailment）

文字蕴涵（Textual entailment，TE）在自然语言处理是一个文字片段之间的定向关系。拥有一个文字片段的含意时，可以从另一个文字如下关系。

范例

- 正向蕴涵

文本T:日本时间2011年3日11日，日本宫城县发生里氏震级9.0强震，造死伤失踪约3万多人。

假设H:日本时间2011年3日11日，日本宫城县发生里氏震级9.0强震。

- 矛盾蕴涵

文本T:张学友在1961年7月10日，生于香港，祖籍天津。

假设H:张学友生于1960年。

- 独立蕴涵

文本T:黎姿与"残障富豪"马廷强结婚。

假设H:马廷强为香港"东方报业集团"创办人之一马惜如之子。

##	7.3 自然语言处理的难点
### 7.3.1 语言环境复杂
自然语言处理语言环境较为复杂，以命名实体识别进行分析，对于同一个汉字某些情况下可以看作实体处理，某些情况就不能看作实体。例如：

- 人名，比如《天龙八部》中“婢子四姊妹一胎孪生，童姥姥给婢子取名为梅剑，这三位妹子是兰剑、竹剑、菊剑。”人物“竹剑”，某些情况下就是指的一种竹子做的剑。
- 地名，比如《射雕英雄传》中“陆庄主知道此人是湖南铁掌帮的帮主”中地点“湖南”，在某种情况下就指代地理方位“湖的那边”。
- 机构名，比如《鹿鼎记》中“这位是莲花堂香主蔡德忠蔡伯伯。”组织机构名(帮派名)“莲花堂”，在某种情况就指代种植莲花的一个地方，变成地点名了。
###	7.3.2 文本结构形式多样
文本内部结构形式多样。还是以自然语言处理中的命名实体识别任务为例子，诸如：

- 人名，人名由姓和名构成。其中姓氏包括单姓和复姓(如：赵、钱、孙、李、慕容、东方、西门等)，名由若干个汉字组成。姓氏的用字范围相对有限，比较容易识别。然而名就比较灵活，既可以用名、字、号表示，也可以使用职务名和用典。比如：“李白、李十二、李翰林 、李供奉、李拾遗、李太白、青莲居士，谪仙人”都是同一个人。
- 地名，一般由若干个字组成地名，可以为作为后缀关键字或者别名(比如：“成都、蓉城、锦城、芙蓉城、锦官城、天府之国”)都是指代一个地方，其中“蓉城、锦城、芙蓉城、锦官城、天府之国”为别名。除了全称的名称之外，还有地理位置代表地名的。比如：“河南、河南省、豫”都是指的一个省份，其中“豫”是简称。
- 组织机构名，组织机构命名方式比较复杂，有些是修饰性的命名，有些表示历史典故，有些表示地理方位，有些表示地名，有些表示风俗习惯和关键字等等。例如：组织名“广州恒大淘宝足球俱乐部”中，“广州”表示地名的成分，“恒大”“淘宝”表示公司名称成分，“足球”是一项体育赛事成分，“俱乐部”是关键字的成分。比如：“四川大学附属中学”(四川省成都市第十二中学)中包括另一个机构名“四川大学”。机构名还可以以简称形式表示，比如：“四川大学附属中学”简称“川大附中”，“成都信息工程大学”简称“成信大”。
###	7.3.3 边界识别限制
 在自然语言处理任务中，边界识别最广泛应用于在命名识别识别当中，边界识别可以分解为两大任务。(1)如何去识别实体的边界？(2)如何去判定实体的类别(诸如：人名、地名、机构名)？中文命名实体识别要比英文命名实体识别更为复杂，一是受中文自身语言特性限制，不同于英语文本中词间有空格界定。二是英文中的实体一般首字母大写容易区分，诸如：‘Jobs was adopted at birth in San Francisco，and raised in a hotbed of counterculture’中，人名乔布斯Jobs的首字母大写，地名旧金山San Francisco首字母也是大写。而中文不具备这样的特征，例如：“周总理忙了一日，早已神困眼倦。”人名“周总理”就很难在一串汉字中识别出来。
###	7.3.4 词义消歧

> 词义消歧


词义消歧是一个自然语言处理和本体论的开放问题。歧义与消歧是自然语言理解中最核心的问题，在词义、句义、篇章含义层次都会出现语言根据上下文语义不同的现象，消歧即指根据上下文确定对象语义的过程。词义消歧即在词语层次上的语义消歧。语义消歧/词义消歧 是自然语言处理任务的一个核心与难点，影响了几乎所有任务的性能，比如搜索引擎、意见挖掘、文本理解与产生、推理等。

> 词性标注与词义消歧

词性标注与词义消歧是相互关联的2个问题，在人的系统他们同时能到满足。但是目前系统一般并不能让2者公用参数，同时输出。语义理解，包括分词、词性标注、词义消歧、句法解析、语义解析 并不是前馈的，是相互依赖的存在反馈的。

词性标注与语义消歧都要依赖上下文来标注，但是词性标注比语义消歧要简单以及成功。原因主要是词性标注的标注集合是确定的，而语义消歧并没有，并且量级要大的多；词性标注的上下文依赖比语义消歧要短。

> 典型例子


许多字词不单只有一个意思，因而我们必须选出使句意最为通顺的解释。
看下面歧义的句子：词意消歧就是分析出特定上下文的词被赋予的哪个意思。

1. 川大学生上网成瘾如患绝症。歧义在于“川大学生”（1）四川大学的学生（2）四川的大学生
1. 两代教授，人格不同。歧义：“两代”（1）两位代理教授（2）两个时代的教授
1. 被控私分国有资产，专家总经理成了被告人。歧义：“专家总经理”（1）专家和总经理（2）有专家身份的总经理
1. 新生市场苦熬淡季。歧义：“新生”（1）新学生的市场（2）新产生的市场
1. 朝鲜十年走近国际社会一步。歧义：“十年走近国际社会一步”（1）每十年就向国际社会走近一步（2）最近十年间向国际社会走近了一步
1. 新汽车牌照。歧义：“新”（1）新的汽车（2）新的牌照
1. 咬死了猎人的狗。歧义：（1）猎人的狗被咬死了（2）把猎人咬死了的那条狗
1. 菜不热了。歧义：“热”（1）指菜凉了（2）指菜不加热了
1. 还欠款四万元。歧义：“还”（1）读huai（2）读hai
1. 北京人多。歧义：（1）北京/人多（2）北京人/多

###	7.3.5 指代消解

> 定义


指代消解（Anaphora Resolution）是自然语言处理的重要内容，在信息抽取时，就用到了指代消解技术。

> 中文的三种典型指代
 
1. 人称代词：李明怕高妈妈一人呆在家里寂寞，【他】便将家里的电视搬了过来。
2. 指示代词：很多人都想创造一个美好的世界留给孩子，【这】可以理解，但不完全正确。
3. 有定描述：贸易制裁似乎成了美国政府在对华关系中惯用的大棒。然而，这【大棒】果真如美国政府所希望的那样灵验吗?


> 典型指代消解

- 显性代词消解

所谓显性代词消解，就是指在篇章中确定显性代词指向哪个名词短语的问题，代词称为指示语或照应语（Anaphor），其所指向的名词短语一般被称为先行语（Antecedent），根据二者之间的先后位置，可分为回指（Anaphora）与预指（Cataphora），其中：如果先行语出现在指示语之前，则称为回指，反之则称为预指。

- 零代词消解

所谓零代词消解，是代词消解中针对零指代（Zero Anaphora）现象的一类特殊的消解。在篇章中，用户能够根据上下文关系推断出的部分经常会省略，而省略的部分（用零代词（Zero Pronoun）表示）在句子中承担着相应的句法成分，并且回指前文中的某个语言学单位。零指代现象在中文中更加常见，（中华语言博大精深。。）近几年随着各大评测任务的兴起开始受到学者们的广泛关注。

- 共指消解

所谓共指消解，是将篇章中指向同一现实世界客观实体（Entity）的词语划分到同一个等价集的过程，其中被划分的词语称为表述或指称语（Mention），形成的等价集称为共指链（Coreference Chain）。在共指消解中，指称语包含：普通名词、专有名词和代词，因此可以将显性代词消解看作是共指消解针对代词的子问题。 
共指消解与显性代词消解不同，它更关注在指称语集合上进行的等价划分，评测方法与显性代词消解也不近相同，通常使用MUC、B-CUBED、CEAF和BLANC评价方法。

指代消解的研究方法大致可以分为基于启发式规则的、基于统计的和基于深度学习的方法，目前看来，基于有监督统计机器学习的消解算法仍然是主流算法。

> 典型例子

指代消解是解决“谁对谁做了 什么”，处理如上所述自然语言的问题，下面看看例子:

1. 美国政府表示仍然支持强势美元，但这到底只是嘴上说说还是要采取果断措施，经济学家对此的看法是否定的。
1. 今天老师又在班会上表扬了自己，但是我觉得还需要继续努力。
1. 三妹拉着葛姐的手说，她老家在偏远的山区，因为和家里赌气才跑到北京打工的，接着她又哭泣起自己的遭遇来。
1. 当他把证书发给小钱时，他对他笑了。
1. 小明和肖华去公园玩,他摔了一跤,他急忙把他扶起来.
1. 星期天,小雨和小英到田老师家补习功课,她一早就打电话给她约好在红旗饭店吃早餐.

## 7.4 自然语言处理展望

2017年，第三届中国人工智能大会上，哈尔滨工业大学刘挺教授对自然语言处理的发展趋势做了一次精彩的归纳，他把这里的趋势分成了十个方面。



> 趋势1：语义表示——从符号表示到分布表示

自然语言处理一直以来都是比较抽象的，都是直接用词汇和符号来表达概念。但是使用符号存在一个问题，比如两个词，它们的词性相近但词形不匹配，计算机内部就会认为它们是两个词。举个例子，荷兰和苏格兰这两个国家名，如果我们在一个语义的空间里，用词汇与词汇组合的方法，把它表示为连续、低维、稠密的向量的话，就可以计算不同层次的语言单元之间的相似度。这种方法同时也可以被神经网络直接使用，是这个领域的一个重要的变化。

从词汇间的组合，到短语、句子，一直到篇章，现在有很多人在做这个事，这和以前的思路是完全不一样的。有了这种方法之后，再用深度学习，就带来了一个很大的转变。原来我们认为自然语言处理要分成几个层次，但是就句法分析来说，它是人为定义的层次，那它是不是一定必要的？这里应该打一个问号。

实际工作中，我们面临着一个课题——信息抽取。我之前和一个单位合作，初衷是我做句法分析，然后他们在我的基础上做信息抽取，相互配合，后来他们发表了一篇论文，与初衷是相悖的，它证明了没有句法分析，也可以直接做端到端的直接的实体关系抽取，这很震撼，不是说现在句法分析没用了，而是我们认为句法分析是人为定义的层次，在端到端的数据量非常充分，可以直接进行信息抽取的时候，那么不用句法分析，也能达到类似的效果。当端到端的数据不充分时，才需要人为划分层次。

> 趋势2：学习模式——从浅层学习到深度学习

浅层到深层的学习模式中，浅层是分步骤走，可能每一步都用了深度学习的方法，实际上各个步骤是串接起来的。直接的深度学习是一步到位的端到端，在这个过程中，我们确实可以看到一些人为贡献的知识，包括该分几层，每层的表示形式，一些规则等，但我们所谓的知识在深度学习里所占的比重确实减小了，主要体现在对深度学习网络结构的调整。

- 趋势3：NLP平台化——从封闭走向开放

以前我们搞研究的，都不是很愿意分享自己的成果，像程序或是数据，现在这些资料彻底开放了，无论是学校还是大企业，都更多地提供平台。NLP领域提供的开放平台越来越多，它的门槛也越来越降低。

语音和语言其实有很大的差别，我认识的好几位国内外的进入NLP的学者，他们发现NLP很复杂，因为像语音识别和语音合成等只有有限的问题，而且这些问题定义非常清晰。但到了自然语言，要处理的问题变得纷繁复杂，尤其是NLP和其他的领域还会有所结合，所以问题非常琐碎。

> 趋势4：语言知识——从人工构建到自动构建

AlphaGo告诉我们，没有围棋高手介入他的开发过程,到AlphaGo最后的版本，它已经不怎么需要看棋谱了。所以AlphaGo在学习和使用过程中都有可能会超出人的想像，因为它并不是简单地跟人学习。

美国有一家文艺复兴公司，它做金融领域的预测，但是这个公司不招金融领域的人，只是招计算机、物理、数学领域的人。这就给了我们一个启发，计算机不是跟人的顶级高手学，而是用自己已有的算法，去直接解决问题。

但是在自然语言处理领域，还是要有大量的显性知识的，但是构造知识的方式也在产生变化。比如，现在我们开始用自动的方法，自动地去发现词汇与词汇之间的关系，像毛细血管一样渗透到各个方面。

> 趋势5：对话机器人——从通用到场景化

最近出现了各种图灵测试的翻版，就是做知识抢答赛来验证人工智能，从产学研应用上来讲就是对话机器人，非常有趣味性和实用价值。

这块的趋势在哪里？我们知道，从Siri刚出来，国内就开始做语音助手了，后来语音助手很快下了马，因为它可以听得到但是听不懂，导致后面的服务跟不上。后来国内把难度降低成了聊天，你不是调戏Siri吗，我就做小冰就跟你聊。但是难度降低了，实用性却跟不上来，所以在用户的留存率上，还是要打个问号。

现在更多的做法和场景结合，降低难度，然后做任务执行，即希望做特定场景时的有用的人机对话。在做人机对话的过程中，大家热情一轮比一轮高涨，但是随后大家发现，很多问题是由于自然语言的理解没有到位，才难以产生真正的突破。

> 趋势6：文本理解与推理——从浅层分析向深度理解迈进

Google等都已经推出了这样的测试机——以阅读理解作为一个深入探索自然语言理解的平台。就是说，给计算机一篇文章，让它去理解，然后人问计算机各种问题，看计算机是否能回答，这样做是很有难度的，因为答案就在这文章里面，人会很刁钻地问计算机。所以说阅读理解是现在竞争的一个很重要的点。

> 趋势7：文本情感分析——从事实性文本到情感文本

多年以前，很多人都在做新闻领域的事实性文本，而如今，搞情感文本分析的似乎更受群众欢迎，这一块这在商业和政府舆情上也都有很好地应用。

> 趋势8：社会媒体处理——从传统媒体到社交媒体

相应的，在社会媒体处理上，从传统媒体到社交媒体的过渡，情感的影响是一方面，大家还会用社交媒体做电影票房的预测，做股票的预测等等。
但是从长远的角度看，社会、人文等的学科与计算机学科的结合是历史性的。比如，在文学、历史学等学科中，有相当一部分新锐学者对本门学科的计算机的大数据非常关心，这两者在碰撞，未来的前景是无限的，而自然语言处理是其中重要的、基础性的技术。

> 趋势9：文本生成——从规范文本到自由文本

文本生成这两年很火，从生成古诗词到生成新闻报道到再到写作文。这方面的研究价值是很大的，它的趋势是从生成规范性的文本到生成自由文本。比如，我们可以从数据库里面生成一个可以模板化的体育报道，这个模板是很规范的。然后我们可以再向自由文本过渡，比如写作文。

> 趋势10：NLP+行业——与领域深度结合，为行业创造价值

最后是谈与企业的合作。现在像银行、电器、医药、司法、教育、金融等的各个领域对NLP的需求都非常多。

我预测NLP首先是会在信息准备的充分的，并且服务方式本身就是知识和信息的领域产生突破。还比如司法领域，它的服务本身也有信息，它就会首先使用NLP。NLP最主要将会用在以下四个领域，医疗、金融、教育和司法。



