# <center> 第 13 章 模型评估 </center>


> 本章导读：本文的初衷源于基于HMM模型序列标注的一个实验，实验完成之后，迫切想知道采用的序列标注模型的好坏，有哪些指标可以度量。于是，就产生了对这一专题进度学习总结，这样也便于其他人参考，节约大家的时间。本文依旧旨在简明扼要梳理出模型评估核心指标，重点达到实用。本章首先介绍基于统计角度的模型评估，然后介绍模型评估的方法，最后对模型选择进行介绍。


## 13.1 统计角度介绍模型概念
### 13.1.1 算法模型

> 概念简述


李航《统计学习方法》一书：统计学习方法是由模型、策略和算法构成的，即统计学习方法的三要素构成，简化：方法=模型+策略+算法

维基百科对数学模型描述：数学模型是对所描述的对象用数学语言所作出的描述和处理。

百度百科对策略描述：策略是学习是一项复杂的智能活动，学习过程与推理过程是紧密相连的，按照学习中使用推理的多少，机器学习所采用的策略大体上可分为4种——机械学习、通过传授学习、类比学习和通过事例学习。学习中所用的推理越多，系统的能力越强。

单纯定义看，不免让人一头雾水，究竟何为模型？还是没有明确的概念，下文将以数学描述+形式化阐述这个问题。首先解决了什么是模型，咱们才能进行模型好坏指标的评价，进而选择适合的学习模型。

模型：所有学习的条件概率分布或者决策函数。

模型的假设空间：包含所有有可能的条件概率分布或者决策函数。

> 实例解析

假设决策函数是输入变量的线性函数，模型的假设空间就是这些线性函数构成的函数集合，假设空间中的模型一般为无穷多个。【现实应用：假设解决序列词性标注的的函数模型M，模型的假设空间的由不同参数构成的M模型。（不是很严谨，辅助理解。）】

形式化表示：假设空间F表示，假设空间可以为决策函数的集合：

    

x，y在输入空间X和输出空间Y上的变量，这时F通常由一个参数向量决定的函数族：

 

参数向量θ取值于n维欧氏空间 ，称为参数空间。

假设空间也可以定义为条件概率集合：

 

其中x和y是定义在输入空间X和Y上的随机变量，这时F通常是一个参数向量的决定的条件概率分布族：

 

参数向量θ取值于n维欧氏空间，称为参数空间。

 注意：由决策函数表示的模型为非概率模型（如上述F函数），由条件概率表示的模型为概率模型（如上述y=f(x)函数）。

###	13.1.2 模型评估和模型选择

>  训练误差和测试误差


好的模型的特征：对已知数据和未知数据都有很好的预测能力。
学习方法评估标准：基于损失函数的模型的训练误差和测试误差为指标。
<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">假设学习到的模型&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170308169-1292852263.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170308169-1292852263.png">&nbsp;,训练误差是模型&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170308169-1292852263.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170308169-1292852263.png">关于训练数据集的平均损失：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170322513-951472577.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170322513-951472577.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">其中N是训练样本容量。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">测试误差是模型 关于测试数据集的平均损失：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170340341-1583763592.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170340341-1583763592.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">其中N’是训练样本容量。</p><h3 style="font-weight: bold; line-height: 1.5; margin-top: 10px; margin-bottom: 10px; white-space: normal; font-size: 16px;"></h3>

>  实例

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">若损失函数是0-1损失时候（0-1损失参考具体相关知识），测试误差就变成了常见的测试数据集上的误差率。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170439044-830539412.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170439044-830539412.png">，这里的I是指示函数，即<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170457841-1145620499.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170457841-1145620499.png">&nbsp;时为1，否则为0。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">相应的，常见的测试数据集上的准确率是：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170510482-1650016951.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170510482-1650016951.png">，这里的I是指示函数，即&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170516919-836002879.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170516919-836002879.png">时为1，否则为0。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">显然：&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170522810-2042241123.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170522810-2042241123.png">&nbsp;</p>

> 实例解析


根据误差率和准确率可知，测试误差反映了学习方法对未知情况的测试数据集的预测能力，测试误差小的方法具有很好的预测能力，更有效的预测。通常将学习方法对未知数据的预测能力称为泛化能力。

由此我们可以应用到现实想NLP模型中，诸如分类模型，当测试误差更小的时候，分类更加准确。聚类模型中，当测试误差较小时候，聚类效果更好等等。那么，在追去测试误差较小时候，就要在训练上下功夫。一味苛求训练效果好，训练误差小，以至于所选择的模型复杂度非常高，这样的低训练误差，能换回好的预测？其实这就容易出现过拟合，如何避免过拟合选择更好的模型？下节继续。

###	13.1.3 过拟合与欠拟合的模型选择

> 何时进行模型选择？


当假设空间含有不同的复杂度（如，不同的参数个数）的模型时，就要面临模型选择问题，以期我们所表达的模型与真实的模型（参数个数）相同或相近。

过拟合：一味追求提高对训练数据的预测能力，所选择模型的复杂度往往比真实模型高，此现象就是过拟合。

过拟合指学习时选择的模型包含的参数过多，以至于出现模型对已经数据预测的好，但是对未知数据预测能力较差。模型选择准则是避免过拟合并且去提高模型预测的能力。

> 实例

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">给出一个训练数据集&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170631966-2146545362.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170631966-2146545362.png">&nbsp;和一个M次多项式的模型</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170641107-687141274.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170641107-687141274.png">&nbsp;</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">完成下面10个数据点的拟合。</p>

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170703029-1638906262.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170703029-1638906262.png">是输入序列集x的观察值</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170712122-857673859.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170712122-857673859.png">是输出序列集y的观察值</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">M 次项式是解决问题的模型</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">W为参数</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">解决如上问题按照经验风险最小化策略求解参数即可，即数学表达：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170720497-1651256328.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170720497-1651256328.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">损失函数为平方损失，1/2是便于计算。然后将模型公式和训练数据代入风险最小化公式：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170734388-1701286946.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170734388-1701286946.png">，最后采用最小二乘法（过程略）求解。</p>

> 实例分析

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">如上图给出M=0,1,3,9的多项式函数的拟合情况，当M=0时，多项式为一个常数，数据拟合很差，当M=1时，多项式曲线为一条直线，拟合依旧差；当M=9时，多项式通过每一个点，训练误差0，从训练数据拟合角度分析，效果最好，但是训练数据本身很多噪音，对未来数据预测能力差，达不到预期的效果。这就是过拟合，虽然训练数据好但是未知数据差。当M=3时，多项式曲线对训练数据拟合效果比较好，对未知数据拟合也很好，其模型也简单，可以选择。总结：模型选择时，不仅仅考虑对已知数据的预测能力，还有考虑对未知数据的预测能力。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">训练误差和测试误差与模型复杂度的关系如下图13-1所示：</p>

<center>

![](https://i.imgur.com/ME9FyuT.jpg)

图13-1 训练误差和测试误差与模型复杂度对比图

</center>


<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">可知，当模型复杂度增大时候，训练误差会逐渐减少趋近于0，而测试误差会先减小到最小值后又增大。当选择模型复杂度过大时，过拟合问题就会出现。</p>

>  补充


<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">NLP序列句子识别标注实例更好理解本节。（以下实例便于理解假设的，不是特别严谨）</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">训练数据集T={(南 B),(海 I),(是 I), (中 I),(国 I),(领 I), (土 I),(。 O) }未知数据P={(不 B), (容 I),(争I),( 议 I),（。 O）}采用BIO标注，B代表句子开始，I代表中间连续词，O代表句子。结束。假设采用模型M识别, M次多项式的模型</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170849576-73700769.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170849576-73700769.png">&nbsp;</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">完成下面句子识别。&nbsp;</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>结果分析：</strong></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">M=0时候，模型一个常数效果很差，识别如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170953685-1502804122.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718170953685-1502804122.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">M=1时候，模型一条直线效果很差，识别如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171003372-2106997227.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171003372-2106997227.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">M=3时候，模型曲线拟合基本合理，且未知数据预测较好，识别如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171016154-1333145983.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171016154-1333145983.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">M=9时候，模型一条直线效果很差，识别如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171029372-78838970.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171029372-78838970.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">训练数据集：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171040529-1949888983.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160718171040529-1949888983.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>实验可知</strong>：左侧为训练模型的数据，右侧为测试模型的数据。当M=0时，训练误差和测试误差都很大；当M=1时，训练误差和测试误差较大；当M=3时，训练误差比M=9的训练误差大，总体训练误差还好，但是，预测误差却小于M=9时的预测误差。综合比较，选择M=3的模型效果会更好。综上，旨在让大家更好理解概念理论知识。</p>

## 13.2 模型评估与选择
### 13.2.1 模型评估的概念

评估准确率的常用技术：保持和随机子抽样、K-折交叉验证、自助方法

统计显著性检验：评估模型准确率

ROC曲线：接收者操作特征曲线比较分类器效果好坏


###	13.2.2 模型评估的评测指标

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>混淆矩阵</strong>：正元组和负元组的合计。详细如表13-1所示：</p>
<center>

表13-1 混淆矩阵表

![](https://i.imgur.com/RuIzvaI.png)

</center>




<strong>评估度量</strong>：（其中P:正样本数 N：负样本数 TP：真正例 TN：真负例 FP：假正例 FN：假负例）评估信息度量如表13-2所示。

<center>

表13-2 评估信息度量表

<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101410341-914028706.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101410341-914028706.png">

</center>






<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><span style="color: rgb(255, 0, 0);">注意：学习器的准确率最好在检验集上估计，检验集的由训练集模型时未使用的含有标记的元组组成数据。</span></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">各参数描述如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">TP（真正例/真阳性）：是指被学习器正确学习的正元组，令TP为真正例的个数。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">TN（真负例/真阴性）：是指被学习器正确学习的负元组，令TN为真负例的个数。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">FP（假正例/假阳性）：是被错误的标记为正元组的负元组。令FP为假正例的个数。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">FN（假负例/假阴性）：是被错误的标记为负元组的正元组。令FN为假负例的个数。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>高准确率的学习模型</strong>：大部分元组应该在混合矩阵的对角线上，而其他为0或者接近0，即FP和FN为0.其本质上是一个对角矩阵时准确率最高。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>准确率</strong>：正确识别的元组所占的比例。又叫做识别率，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<strong><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101511372-1915794539.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101511372-1915794539.png"></strong></p>
###	13.2.3 词性标注为例分析模型评估


词性标注为例分析模型评估详细信息如表13-3所示：
<center>

表13-3 词性标注为例分析模型评估表

<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101654841-775463264.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101654841-775463264.png">

</center>

<strong>错误率：</strong>错误识别元组所占的比例，又叫误识别率，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101732060-581925635.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101732060-581925635.png">&nbsp;&nbsp;或者1-accuracy(M)</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">检验时，应采用检验集未加入训练集的数据，当采用训练集估计模型时，为再带入误差，这种称为乐观估计。准确率可以度量正确标注的百分比，但是不能正确度量错误率。诸如样本不平衡时，即负样本是稀疏却是感兴趣的。比如：欺诈、癌症等。这种情况下应使用灵敏性特效性度量。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>灵敏度又叫真正识别率</strong>：正确识别的正元组的百分比，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101755857-1756734763.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101755857-1756734763.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>特效性又叫真负例率</strong>：正确识别的正元组的百分比，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101815794-1920529673.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101815794-1920529673.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>准确率的灵敏度和特效性的函数关系</strong>：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101827951-594261296.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101827951-594261296.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>精度</strong>：精确性的度量即标记为正元组实际为正元组的百分比，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">、<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101836763-1192934474.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101836763-1192934474.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>召回率</strong>：完全性的度量即正元组标记为正的百分比，公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101849372-2103249073.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101849372-2103249073.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">精度和召回率之间趋向于逆关系，有可能以降低一个指标提升另一个指标。此刻两个指标预想达到综合引出了F度量值</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>F度量</strong>（又叫F分数）：用精度和召回率的方法把他们组合到一个度量中。公式如下：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101900544-649129756.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101900544-649129756.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101906935-775120886.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101906935-775120886.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>比较</strong>：F度量是精度和召回率的调和均值，赋予精度和召回率相等的权重，&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101915919-162492745.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101915919-162492745.png">度量是精度和召回率加权度量，它赋予召回率权重是精度的β倍，诸如中文词汇中，常用词的权重比生僻词的权重大是一样的道理，也符合实际应用。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><span style="color: rgb(255, 0, 0);">注意：当元组属于多个类时，不适合使用准确率。当数据均衡分布即正负元组基本相当时，准确率效果最好，而召回率、特效性、精度、F和&nbsp;<img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101915919-162492745.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719101915919-162492745.png">更适合于样本分布不均的情况。</span></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong></strong></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><em></em></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"></p>
###	13.2.4 模型评估的几种方法

模型评估包括多种方法，常见的评估流程如图13-2所示。

<center>
![](https://i.imgur.com/CRWjZyh.png)

图13-2 模型评估流程图
</center>

1）随机二次抽样评估准确率：是保持方法的一种变形，将保持方法重复K次，总准确率估计是每次迭代准确率的平均值</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">2）K-折交叉验证评估准确率：（建议10折）</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">K-折交叉验证：将初始的数据随机分为大小大致相同的K份，训练和检验进行K次，如第1次迭代第一份数据作为检查集，其余K-1份作为训练集，第2次迭代。第二份数据作为检验集，其余K-1份作为训练集，以此类推直到第K份数据作为检验集为止。此方法每份样本用于训练的次数一致且每份样本只作为一次检验集。准确率是K次迭代正确元组总数除以初始数据元组总数。一般建议采用10-折交叉验证估计准确率，因为它的偏移和方差较低。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">3）自助法评估准确率：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">自助法有放回的均匀抽样，常用632自助法。即63.2%原数据将出现在自助样本中。而其余38.8%元数据形成检验集。</p><h2 style="font-size: 21px; line-height: 1.5; font-weight: bold; margin-top: 10px; margin-bottom: 10px; white-space: normal;"></h2>

## 13.3 ROC曲线比较学习器模型

<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>成本效益</strong>（风险增益）：如错误的预测癌症患者没有患病比将没有患病的病人归类癌症的代价大等等事件，据此给于不同的权重。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">ROC曲线又叫接受者操作特征曲线，比较两个学习器模型的可视化工具，横坐标参数假正例率，纵坐标参数是真正例率。以此汇聚成的曲线，越靠近对角线（随机猜测线）模型越不好。</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>真正例率</strong>（召回率）：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719102027154-1584845635.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719102027154-1584845635.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>假正例率</strong>：</p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><img src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719102035451-93411190.png" alt="" style="border: 0px;" _src="http://images2015.cnblogs.com/blog/380252/201607/380252-20160719102035451-93411190.png"></p><p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;"><strong>实例解析</strong>：以10个检验元组的概率分类器为例绘制ROC曲线。数据如表13-4所示</p>

<center>
表13-4 检验元组数据表

![](https://i.imgur.com/9TJKhbX.png)

</center>


<p style="line-height: 24px; margin: 10px auto; font-size: 15px; white-space: normal;">由以上数据绘制ROC曲线如图13-3所示：</p>

<center>

![](https://i.imgur.com/JjoM0mI.png)

图13-3 ROC曲线图
</center>




由此可知，对角线为随机猜测线，模型的ROC曲线越靠近对角线，模型的准确率越低。如果很好的模型，真正比例比较多，曲线应是陡峭的从0开始上升，后来遇到真正比例越来越少，假正比例元组越来越多，曲线平缓变的更加水平。完全正确的模型面积为1。</p>